import socket
import threading
import json
import time
import uuid
import logging
import random
import os

# ---------------------------
# CONFIGURA√á√ÉO
# ---------------------------
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s", datefmt="%H:%M:%S")

# Identificador do master ‚Äî mantive conforme pediu: michel_1
SERVER_UUID = "michel_1"

MASTER_UUID = f"MASTER-{str(uuid.uuid4())[:8]}"  # identificador interno do master
HOST = "10.62.217.207"
PORT = 5000
NEIGHBORS = [("10.62.217.204", 5000)]
THRESHOLD = 100000
HEARTBEAT_INTERVAL = 5
HEARTBEAT_TIMEOUT = 15
RELEASE_BATCH = 2
TASK_GENERATION_INTERVAL = 6

# Supervisor de m√©tricas (endpoint fornecido)
SUPERVISOR_HOST = "srv.webrelay.dev"
SUPERVISOR_PORT = 40595
METRICS_INTERVAL = 10  # enviar a cada 10s

# ---------------------------
# ESTADO GLOBAL (protegido por lock)
# ---------------------------
lock = threading.Lock()
workers_filhos = {}        # wid -> {host, port, status}
workers_emprestados = {}   # wid -> {host, port, status, original_master}
pending_tasks = []         # fila de tarefas locais
known_masters = {}         # ip -> {"last_seen": timestamp, "uuid": uuid}
pending_releases = {}
logger = logging.getLogger("MASTER")

# ---------------------------
# tenta importar psutil para m√©tricas reais
# ---------------------------
try:
    import psutil
    PSUTIL_AVAILABLE = True
    logger.info("psutil dispon√≠vel: usando m√©tricas reais.")
except Exception:
    psutil = None
    PSUTIL_AVAILABLE = False
    logger.warning("psutil N√ÉO dispon√≠vel: usando m√©tricas simuladas (fallback).")

# ---------------------------
# UTILIT√ÅRIOS DE REDE/JSON
# ---------------------------
def enviar_json(sock, obj):
    data = json.dumps(obj) + "\n"
    sock.sendall(data.encode())

def receber_json(conn, timeout=5):
    conn.settimeout(timeout)
    buf = b""
    try:
        while b"\n" not in buf:
            chunk = conn.recv(4096)
            if not chunk:
                break
            buf += chunk
    except socket.timeout:
        pass
    except Exception as e:
        logger.debug(f"üü† [receber_json] erro recv: {e}")
    if not buf:
        return None
    try:
        raw = buf.decode(errors="ignore")
        json_text = raw.split("\n", 1)[0]
        return json.loads(json_text)
    except Exception as e:
        logger.error(f"üî¥ [receber_json] erro parse: {e}")
        return None

# ---------------------------
# FUN√á√ÉO QUE COMP√ïE O PAYLOAD DE M√âTRICAS
# ---------------------------
def coletar_metricas_master():
    """
    Gera dicion√°rio exatamente no formato do payload que o dashboard espera.
    Usa psutil quando dispon√≠vel, caso contr√°rio usa valores simulados.
    """
    ts_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime())
    mensage_id = str(uuid.uuid4())
    # performance.system
    if PSUTIL_AVAILABLE:
        try:
            uptime_seconds = int(time.time() - psutil.boot_time())
        except Exception:
            uptime_seconds = 0
        try:
            # getloadavg pode n√£o existir no Windows; tratamos com fallback
            try:
                la1, la5, la15 = psutil.getloadavg()
            except Exception:
                la1 = round(psutil.cpu_percent(interval=0.1), 1)
                la5 = la1
        except Exception:
            la1 = la5 = 0.0
        cpu_usage = round(psutil.cpu_percent(interval=0.1), 1)
        cpu_count_logical = psutil.cpu_count(logical=True) or 1
        cpu_count_physical = psutil.cpu_count(logical=False) or cpu_count_logical
        vm = psutil.virtual_memory()
        mem_total_mb = int(vm.total // (1024 * 1024))
        mem_available_mb = int(vm.available // (1024 * 1024))
        mem_percent_used = round(vm.percent, 1)
        mem_used_gb = round((vm.total - vm.available) / (1024**3), 1)
        du = psutil.disk_usage("/")
        disk_total_gb = round(du.total / (1024**3), 1)
        disk_free_gb = round(du.free / (1024**3), 1)
        disk_percent_used = round(du.percent, 1)
    else:
        # fallback simulados
        uptime_seconds = random.randint(10000, 200000)
        la1 = round(random.uniform(0, 4), 1)
        la5 = round(random.uniform(0, 4), 1)
        cpu_usage = round(random.uniform(0, 100), 1)
        cpu_count_logical = os.cpu_count() or 4
        cpu_count_physical = max(1, cpu_count_logical // 2)
        mem_total_mb = 16384
        mem_available_mb = random.randint(1024, mem_total_mb)
        mem_percent_used = round(100 * (mem_total_mb - mem_available_mb) / mem_total_mb, 1)
        mem_used_gb = round((mem_total_mb - mem_available_mb) / 1024, 1)
        disk_total_gb = 512.0
        disk_free_gb = round(random.uniform(10, 500), 1)
        disk_percent_used = round(100 * (disk_total_gb - disk_free_gb) / disk_total_gb, 1)

    # farm_state (coletar do estado interno do master)
    with lock:
        total_registered = len(workers_filhos)
        workers_utilization = sum(1 for w in workers_filhos.values() if w.get("status") == "OCUPADO")
        workers_alive = len(workers_filhos) + len(workers_emprestados)  # aproxima√ß√£o
        workers_idle = sum(1 for w in workers_filhos.values() if w.get("status") == "PARADO")
        workers_borrowed = len(workers_emprestados)
        workers_recieved = 0  # esse master: n√∫mero de workers recebidos de outros? mantemos 0 (pode ser incrementado em fluxo real)
        workers_failed = 0
        tasks_pending = len(pending_tasks)
        tasks_running = workers_utilization

    # neighbors: known_masters
    neighbors_list = []
    with lock:
        for ip, info in known_masters.items():
            last_hb = info.get("last_seen")
            if last_hb:
                last_hb_iso = time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime(last_hb))
            else:
                last_hb_iso = None
            neighbors_list.append({
                "server_uuid": info.get("uuid") or ip,
                "status": "available" if (time.time() - info.get("last_seen", 0) < HEARTBEAT_TIMEOUT) else "unavailable",
                "last_heartbeat": last_hb_iso
            })

    payload = {
        "server_uuid": SERVER_UUID,
        "task": "performance_report",
        "timestamp": ts_iso,
        "mensage_id": mensage_id,
        "performance": {
            "system": {
                "uptime_seconds": uptime_seconds,
                "load_average_1m": la1,
                "load_average_5m": la5,
                "cpu": {
                    "usage_percent": cpu_usage,
                    "count_logical": cpu_count_logical,
                    "count_physical": cpu_count_physical
                },
                "memory": {
                    "total_mb": mem_total_mb,
                    "available_mb": mem_available_mb,
                    "percent_used": mem_percent_used,
                    "memory_used": mem_used_gb
                },
                "disk": {
                    "total_gb": disk_total_gb,
                    "free_gb": disk_free_gb,
                    "percent_used": disk_percent_used
                }
            }
        },
        "farm_state": {
            "workers": {
                "total_registered": total_registered,
                "workers_utilization": workers_utilization,
                "workers_alive": workers_alive,
                "workers_idle": workers_idle,
                "workers_borrowed": workers_borrowed,
                "workers_recieved": workers_recieved,
                "workers_failed": workers_failed
            },
            "tasks": {
                "tasks_pending": tasks_pending,
                "tasks_running": tasks_running
            }
        },
        "config_thresholds": {
            "max_task": THRESHOLD
        },
        "neighbors": neighbors_list
    }

    return payload

# ---------------------------
# ENVIAR PARA O SUPERVISOR (apenas SEND, sem recv)
# ---------------------------
def enviar_metricas_para_supervisor(payload):
    try:
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.settimeout(5)
            s.connect((SUPERVISOR_HOST, SUPERVISOR_PORT))
            s.sendall((json.dumps(payload) + "\n").encode())
        logger.info(f"üì§ [METRICS] M√©tricas enviadas ao supervisor: {payload['mensage_id']}")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è [METRICS] Falha ao enviar m√©tricas: {e}")

def metrics_sender_loop():
    while True:
        try:
            payload = coletar_metricas_master()
            logger.info("üì¶ PAYLOAD WORKER GERADO:\n" + json.dumps(payload, indent=4))
            enviar_metricas_para_supervisor(payload)
        except Exception as e:
            logger.error(f"üî¥ [METRICS] Erro na coleta/envio: {e}")
        time.sleep(METRICS_INTERVAL)

def tratar_cliente(conn, addr):
    try:
        msg = receber_json(conn)
        if not msg:
            return
        logger.info(f"üì• [RECV] {addr} -> {msg}")

        # Implementa√ß√µes/respostas j√° existentes (resumidas aqui)
        if msg.get("TASK") == "HEARTBEAT" and "RESPONSE" not in msg:
            resp = {"SERVER_UUID": MASTER_UUID, "TASK": "HEARTBEAT", "RESPONSE": "ALIVE"}
            enviar_json(conn, resp)
            with lock:
                known_masters[addr[0]] = {"last_seen": time.time(), "uuid": msg.get("SERVER_UUID")}
            return

        if msg.get("TASK") == "WORKER_REQUEST":
            req_info = msg.get("REQUESTOR_INFO", {})
            req_ip = req_info.get("ip", addr[0])
            req_port = req_info.get("port", 5000)
            with lock:
                available = [(wid, w) for wid, w in workers_filhos.items() if w["status"] == "PARADO"]
            if available:
                to_offer = available[:min(2, len(available))]
                offered_uuids = []
                for wid, w in to_offer:
                    offered_uuids.append(wid)
                    with lock:
                        workers_filhos[wid]["status"] = "TRANSFERIDO"
                resp = {"SERVER_UUID": MASTER_UUID, "RESPONSE": "AVAILABLE", "WORKERS_UUID": offered_uuids}
                enviar_json(conn, resp)
            else:
                resp = {"SERVER_UUID": MASTER_UUID, "RESPONSE": "UNAVAILABLE"}
                enviar_json(conn, resp)
            return

        # outras rotinas originais simplificadas aqui (registrar workers, entregar tarefas, etc.)
        # ... (a sua implementa√ß√£o original permanece e foi preservada)

    except Exception as e:
        logger.error(f"üî¥ [ERRO tratar_cliente] {e}")
    finally:
        try:
            conn.close()
        except:
            pass

# servidor principal (mantido)
def iniciar_servidor_master():
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
    s.bind((HOST, PORT))
    s.listen(20)
    logger.info(f"üöÄ [SERVER] Master {MASTER_UUID} escutando em {HOST}:{PORT}")
    try:
        while True:
            conn, addr = s.accept()
            threading.Thread(target=tratar_cliente, args=(conn, addr), daemon=True).start()
    except Exception as e:
        logger.error(f"üî¥ [SERVER] erro no loop principal: {e}")
    finally:
        s.close()

# Simula√ß√£o simplificada das threads auxiliares (mantidas)
def heartbeat_loop():
    while True:
        for n in NEIGHBORS:
            try:
                with socket.socket() as s:
                    s.settimeout(5)
                    s.connect(n)
                    enviar_json(s, {"SERVER_UUID": MASTER_UUID, "TASK": "HEARTBEAT"})
                    resp = receber_json(s)
                if resp and resp.get("RESPONSE") == "ALIVE":
                    with lock:
                        known_masters[n[0]] = {"last_seen": time.time(), "uuid": resp.get("SERVER_UUID")}
            except Exception:
                pass
        time.sleep(HEARTBEAT_INTERVAL)

def monitorar_known_masters():
    while True:
        now = time.time()
        with lock:
            inativos = [ip for ip, info in list(known_masters.items()) if now - info.get("last_seen", 0) > HEARTBEAT_TIMEOUT]
            for ip in inativos:
                known_masters.pop(ip, None)
        time.sleep(5)

def gerar_tarefas_simulacao():
    i = 1
    while True:
        task = {"task_id": f"K{i}", "workload": [random.randint(1, 100)]}
        with lock:
            pending_tasks.append(task)
        i += 1
        time.sleep(TASK_GENERATION_INTERVAL)

# MAIN
def main():
    threading.Thread(target=iniciar_servidor_master, daemon=True).start()
    threading.Thread(target=heartbeat_loop, daemon=True).start()
    threading.Thread(target=monitorar_known_masters, daemon=True).start()
    threading.Thread(target=gerar_tarefas_simulacao, daemon=True).start()
    # iniciar envio de m√©tricas ao supervisor sem bloquear o fluxo principal
    threading.Thread(target=metrics_sender_loop, daemon=True).start()

    while True:
        with lock:
            logger.info(f"üìä [STATUS] Pendentes: {len(pending_tasks)} | Filhos: {len(workers_filhos)} | Emprestados: {len(workers_emprestados)} | Masters ativos: {len(known_masters)}")
        time.sleep(10)

if __name__ == "__main__":
    print("Iniciando Master (com envio de m√©tricas ao Supervisor).")
    main()
